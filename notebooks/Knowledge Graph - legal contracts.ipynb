{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9cb7d5e",
   "metadata": {},
   "source": [
    "# Building Knowledge Graphs with Neo4J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf191f5",
   "metadata": {},
   "source": [
    "GraphRAG (Graphs + Retrieval Augmented Generation) combines the strengths of Retrieval Augmented Generation (RAG) and Query-Focused Summarization (QFS) to effectively handle complex queries over large text datasets. While RAG excels in fetching precise information, it struggles with broader queries that require thematic understanding, a challenge that QFS addresses but cannot scale well. GraphRAG integrates these approaches to offer responsive and thorough querying capabilities across extensive, diverse text corpora.\n",
    "\n",
    "The pipeline contains the following steps:\n",
    "\n",
    "- Use LlamaParse to parse PDF documents and extract readable text\n",
    "- Employ a large language model to classify the contract type, enabling context-aware processing\n",
    "- Leverage LlamaExtract to extract different sets of relevant attributes tailored to each specific contract category based on the classification\n",
    "- Store all structured information into a Neo4j knowledge graph, creating a rich, queryable representation that captures both content and intricate relationships within legal documents\n",
    "\n",
    "Source:\n",
    "\n",
    "- [LlamaIndex docs](https://docs.llamaindex.ai/en/latest/examples/cookbooks/GraphRAG_v2/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d72c2d",
   "metadata": {},
   "source": [
    "## 1. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92166c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from datetime import date\n",
    "from typing import List, Optional\n",
    "\n",
    "from neo4j import AsyncGraphDatabase\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from llama_cloud_services.extract import (\n",
    "    ExtractConfig,\n",
    "    ExtractMode,\n",
    "    LlamaExtract,\n",
    "    SourceText,\n",
    ")\n",
    "from llama_cloud_services.parse import LlamaParse\n",
    "\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cbfa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = os.getenv(\"NEO4J_DB_URL\")\n",
    "username = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "neo4j_driver = AsyncGraphDatabase.driver(\n",
    "    db_url,\n",
    "    auth=(\n",
    "        username,\n",
    "        password,\n",
    "    ),\n",
    ")\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "with GraphDatabase.driver(db_url, auth=(username, password)) as driver:\n",
    "    driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1be968",
   "metadata": {},
   "source": [
    "## 2. Parsing Contract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43886f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMACLOUD_API_KEY=os.getenv(\"LLAMACLOUD_API_KEY\")\n",
    "len(LLAMACLOUD_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672eee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parser with specified mode\n",
    "parser = LlamaParse(parse_mode=\"parse_page_without_llm\", api_key=LLAMACLOUD_API_KEY)\n",
    "\n",
    "# Define the PDF file to parse\n",
    "pdf_path = \"../data/legal_agreement.pdf\"\n",
    "\n",
    "# Parse the document asynchronously\n",
    "results = await parser.aparse(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25295042",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.pages[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a17805",
   "metadata": {},
   "source": [
    "## 3. Contract Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c5bff",
   "metadata": {},
   "source": [
    "In this example, we want to classify incoming contracts. They can either be Affiliate Agreements or Co Branding. We define a classification prompt below, and ask the LLM to return the reason for the classification as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36339448",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prompt = \"\"\"You are a legal document classification assistant.\n",
    "Your task is to identify the most likely contract type based on the content of the first 10 pages of a contract.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Read the contract excerpt below (up to the first 10 pages).\n",
    "\n",
    "Review the list of possible contract types.\n",
    "\n",
    "Choose the single most appropriate contract type from the list.\n",
    "\n",
    "Justify your classification briefly, based only on the information in the excerpt.\n",
    "\n",
    "Contract Excerpt:\n",
    "{contract_text}\n",
    "\n",
    "Possible Contract Types:\n",
    "{contract_type_list}\n",
    "\n",
    "Output Format:\n",
    "<Reason>brief_justification</Reason>\n",
    "<ContractType>chosen_type_from_list</ContractType>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "def extract_reason_and_contract_type(text: str) -> dict:\n",
    "    reason_match = re.search(r\"<Reason>(.*?)</Reason>\", text, re.DOTALL)\n",
    "    reason = reason_match.group(1).strip() if reason_match else None\n",
    "\n",
    "    contract_type_match = re.search(\n",
    "        r\"<ContractType>(.*?)</ContractType>\", text, re.DOTALL\n",
    "    )\n",
    "    contract_type = (\n",
    "        contract_type_match.group(1).strip() if contract_type_match else None\n",
    "    )\n",
    "\n",
    "    return {\"reason\": reason, \"contract_type\": contract_type}\n",
    "\n",
    "async def classify_contract(\n",
    "    contract_text: str, contract_types: list[str]\n",
    ") -> dict:\n",
    "    prompt = classification_prompt.format(\n",
    "        contract_text=contract_text, contract_type_list=contract_types\n",
    "    )\n",
    "    history = [ChatMessage(role=\"user\", content=prompt)]\n",
    "\n",
    "    response = await llm.achat(history)\n",
    "    return extract_reason_and_contract_type(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_types = [\"Affiliate_Agreements\", \"Co_Branding\"]\n",
    "\n",
    "# Take only the first 10 pages for contract classification as input\n",
    "file_content = \" \".join([el.text for el in results.pages[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453990f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = await classify_contract(file_content, contract_types)\n",
    "classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14819c3a",
   "metadata": {},
   "source": [
    "## 4. Setting up Structured Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecc4c8",
   "metadata": {},
   "source": [
    "Next, we define some schemas which we can use to extract relevant information from our contracts with. The fields we define are a mix of summarization and structured data extraction.\n",
    "\n",
    "Here we define two Pydantic models: `Location` captures structured address information with optional fields for country, state, and address, while `Party` represents contract parties with a required name and optional location details. The Field descriptions help guide the extraction process by telling the LLM exactly what information to look for in each field.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39992889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Location(BaseModel):\n",
    "    \"\"\"Location information with structured address components.\"\"\"\n",
    "\n",
    "    country: Optional[str] = Field(None, description=\"Country\")\n",
    "    state: Optional[str] = Field(None, description=\"State or province\")\n",
    "    address: Optional[str] = Field(None, description=\"Street address or city\")\n",
    "\n",
    "\n",
    "class Party(BaseModel):\n",
    "    \"\"\"Party information with name and location.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Party name\")\n",
    "    location: Optional[Location] = Field(\n",
    "        None, description=\"Party location details\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseContract(BaseModel):\n",
    "    \"\"\"Base contract class with common fields.\"\"\"\n",
    "\n",
    "    parties: Optional[List[Party]] = Field(\n",
    "        None, description=\"All contracting parties\"\n",
    "    )\n",
    "    agreement_date: Optional[str] = Field(\n",
    "        None, description=\"Contract signing date. Use YYYY-MM-DD\"\n",
    "    )\n",
    "    effective_date: Optional[str] = Field(\n",
    "        None, description=\"When contract becomes effective. Use YYYY-MM-DD\"\n",
    "    )\n",
    "    expiration_date: Optional[str] = Field(\n",
    "        None, description=\"Contract expiration date. Use YYYY-MM-DD\"\n",
    "    )\n",
    "    governing_law: Optional[str] = Field(\n",
    "        None, description=\"Governing jurisdiction\"\n",
    "    )\n",
    "    termination_for_convenience: Optional[bool] = Field(\n",
    "        None, description=\"Can terminate without cause\"\n",
    "    )\n",
    "    anti_assignment: Optional[bool] = Field(\n",
    "        None, description=\"Restricts assignment to third parties\"\n",
    "    )\n",
    "    cap_on_liability: Optional[str] = Field(\n",
    "        None, description=\"Liability limit amount\"\n",
    "    )\n",
    "\n",
    "\n",
    "class AffiliateAgreement(BaseContract):\n",
    "    \"\"\"Affiliate Agreement extraction.\"\"\"\n",
    "\n",
    "    exclusivity: Optional[str] = Field(\n",
    "        None, description=\"Exclusive territory or market rights\"\n",
    "    )\n",
    "    non_compete: Optional[str] = Field(\n",
    "        None, description=\"Non-compete restrictions\"\n",
    "    )\n",
    "    revenue_profit_sharing: Optional[str] = Field(\n",
    "        None, description=\"Commission or revenue split\"\n",
    "    )\n",
    "    minimum_commitment: Optional[str] = Field(\n",
    "        None, description=\"Minimum sales targets\"\n",
    "    )\n",
    "\n",
    "\n",
    "class CoBrandingAgreement(BaseContract):\n",
    "    \"\"\"Co-Branding Agreement extraction.\"\"\"\n",
    "\n",
    "    exclusivity: Optional[str] = Field(\n",
    "        None, description=\"Exclusive co-branding rights\"\n",
    "    )\n",
    "    ip_ownership_assignment: Optional[str] = Field(\n",
    "        None, description=\"IP ownership allocation\"\n",
    "    )\n",
    "    license_grant: Optional[str] = Field(\n",
    "        None, description=\"Brand/trademark licenses\"\n",
    "    )\n",
    "    revenue_profit_sharing: Optional[str] = Field(\n",
    "        None, description=\"Revenue sharing terms\"\n",
    "    )\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    \"Affiliate_Agreements\": AffiliateAgreement,\n",
    "    \"Co_Branding\": CoBrandingAgreement,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ff6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = LlamaExtract(api_key=LLAMACLOUD_API_KEY)\n",
    "\n",
    "agent = extractor.create_agent(\n",
    "    name=f\"extraction_workflow_import_{uuid.uuid4()}\",\n",
    "    data_schema=mapping[classification[\"contract_type\"]],\n",
    "    config=ExtractConfig(\n",
    "        extraction_mode=ExtractMode.BALANCED,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = await agent.aextract(\n",
    "    files=SourceText(\n",
    "        text_content=\" \".join([el.text for el in results.pages]),\n",
    "        filename=pdf_path,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result), [m for m in dir(result) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4dcce",
   "metadata": {},
   "source": [
    "## 5. Stores Entities & Relations to Neo4J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8138bb",
   "metadata": {},
   "source": [
    "The final step is to take our extracted structured information and build a knowledge graph that represents the relationships between contract entities. We need to define a graph model that specifies how our contract data should be organized as nodes and relationships in Neo4j.\n",
    "\n",
    "Our graph model consists of three main node types:\n",
    "\n",
    "- **Contract nodes** store the core agreement information including dates, terms, and legal clauses\n",
    "- **Party nodes** represent the contracting entities with their names\n",
    "- **Location nodes** capture geographic information with address components.\n",
    "\n",
    "Now we'll import our extracted contract data into Neo4j according to our defined graph model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe912261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_query = \"\"\"\n",
    "WITH $contract AS contract\n",
    "MERGE (c:Contract {path: $path})\n",
    "SET c += apoc.map.clean(contract, [\"parties\", \"agreement_date\", \"effective_date\", \"expiration_date\"], [])\n",
    "// Cast to date\n",
    "SET c.agreement_date = date(contract.agreement_date),\n",
    "    c.effective_date = date(contract.effective_date),\n",
    "    c.expiration_date = date(contract.expiration_date)\n",
    "\n",
    "// Create parties with their locations\n",
    "WITH c, contract\n",
    "UNWIND coalesce(contract.parties, []) AS party\n",
    "MERGE (p:Party {name: party.name})\n",
    "MERGE (c)-[:HAS_PARTY]->(p)\n",
    "\n",
    "// Create location nodes and link to parties\n",
    "WITH p, party\n",
    "WHERE party.location IS NOT NULL\n",
    "MERGE (p)-[:HAS_LOCATION]->(l:Location)\n",
    "SET l += party.location\n",
    "\"\"\"\n",
    "\n",
    "response = await neo4j_driver.execute_query(\n",
    "    import_query, contract=result.data, path=pdf_path\n",
    ")\n",
    "response.summary.counters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa6215",
   "metadata": {},
   "source": [
    "## 6. Bringing it All Together in a Workflow\n",
    "\n",
    "Finally, we can combine all of this logic into one single executable agentic workflow. Let's make it so that the workflow can run by accepting a single PDF, adding new entries to our Neo4j graph each time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliage_extraction_agent = extractor.create_agent(\n",
    "    name=\"Affiliate_Extraction\",\n",
    "    data_schema=AffiliateAgreement,\n",
    "    config=ExtractConfig(\n",
    "        extraction_mode=ExtractMode.BALANCED,\n",
    "    ),\n",
    ")\n",
    "cobranding_extraction_agent = extractor.create_agent(\n",
    "    name=\"CoBranding_Extraction\",\n",
    "    data_schema=CoBrandingAgreement,\n",
    "    config=ExtractConfig(\n",
    "        extraction_mode=ExtractMode.BALANCED,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    Event,\n",
    "    Context,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    step,\n",
    ")\n",
    "\n",
    "\n",
    "class ClassifyDocEvent(Event):\n",
    "    parsed_doc: str\n",
    "    pdf_path: str\n",
    "\n",
    "\n",
    "class ExtactAffiliate(Event):\n",
    "    file_path: str\n",
    "\n",
    "\n",
    "class ExtractCoBranding(Event):\n",
    "    file_path: str\n",
    "\n",
    "\n",
    "class BuildGraph(Event):\n",
    "    file_path: str\n",
    "    data: dict\n",
    "\n",
    "\n",
    "class KnowledgeGraphBuilder(Workflow):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parser: LlamaParse,\n",
    "        affiliate_extract_agent: LlamaExtract,\n",
    "        branding_extract_agent: LlamaExtract,\n",
    "        classification_prompt: str,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.parser = parser\n",
    "        self.affiliate_extract_agent = affiliate_extract_agent\n",
    "        self.branding_extract_agent = branding_extract_agent\n",
    "        self.classification_prompt = classification_prompt\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "    @step\n",
    "    async def parse_file(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> ClassifyDocEvent:\n",
    "        results = await self.parser.aparse(ev.pdf_path)\n",
    "        parsed_doc = \" \".join([el.text for el in results.pages[:10]])\n",
    "        return ClassifyDocEvent(parsed_doc=parsed_doc, pdf_path=ev.pdf_path)\n",
    "\n",
    "    @step\n",
    "    async def classify_contract(\n",
    "        self, ctx: Context, ev: ClassifyDocEvent\n",
    "    ) -> ExtactAffiliate | ExtractCoBranding | StopEvent:\n",
    "        prompt = self.classification_prompt.format(\n",
    "            contract_text=ev.parsed_doc,\n",
    "            contract_type_list=[\"Affiliate_Agreements\", \"Co_Branding\"],\n",
    "        )\n",
    "        history = [ChatMessage(role=\"user\", content=prompt)]\n",
    "\n",
    "        response = await llm.achat(history)\n",
    "        reason_match = re.search(\n",
    "            r\"(.*?)\", response.message.content, re.DOTALL\n",
    "        )\n",
    "        reason = reason_match.group(1).strip() if reason_match else None\n",
    "\n",
    "        contract_type_match = re.search(\n",
    "            r\"(.*?)\",\n",
    "            response.message.content,\n",
    "            re.DOTALL,\n",
    "        )\n",
    "        contract_type = (\n",
    "            contract_type_match.group(1).strip()\n",
    "            if contract_type_match\n",
    "            else None\n",
    "        )\n",
    "        if contract_type == \"Affiliate_Agreements\":\n",
    "            return ExtactAffiliate(file_path=ev.pdf_path)\n",
    "        elif contract_type == \"Co_Branding\":\n",
    "            return ExtractCoBranding(file_path=ev.pdf_path)\n",
    "        else:\n",
    "            return StopEvent()\n",
    "\n",
    "    @step\n",
    "    async def extract_affiliate(\n",
    "        self, ctx: Context, ev: ExtactAffiliate\n",
    "    ) -> BuildGraph:\n",
    "        result = await self.affiliate_extract_agent.aextract(ev.file_path)\n",
    "        return BuildGraph(data=result.data, file_path=ev.file_path)\n",
    "\n",
    "    @step\n",
    "    async def extract_co_branding(\n",
    "        self, ctx: Context, ev: ExtractCoBranding\n",
    "    ) -> BuildGraph:\n",
    "        result = await self.branding_extract_agent.aextract(ev.file_path)\n",
    "        return BuildGraph(data=result.data, file_path=ev.file_path)\n",
    "\n",
    "    @step\n",
    "    async def build_graph(self, ctx: Context, ev: BuildGraph) -> StopEvent:\n",
    "        import_query = \"\"\"\n",
    "    WITH $contract AS contract\n",
    "    MERGE (c:Contract {path: $path})\n",
    "    SET c += apoc.map.clean(contract, [\"parties\", \"agreement_date\", \"effective_date\", \"expiration_date\"], [])\n",
    "    // Cast to date\n",
    "    SET c.agreement_date = date(contract.agreement_date),\n",
    "      c.effective_date = date(contract.effective_date),\n",
    "      c.expiration_date = date(contract.expiration_date)\n",
    "\n",
    "    // Create parties with their locations\n",
    "    WITH c, contract\n",
    "    UNWIND coalesce(contract.parties, []) AS party\n",
    "    MERGE (p:Party {name: party.name})\n",
    "    MERGE (c)-[:HAS_PARTY]->(p)\n",
    "\n",
    "    // Create location nodes and link to parties\n",
    "    WITH p, party\n",
    "    WHERE party.location IS NOT NULL\n",
    "    MERGE (p)-[:HAS_LOCATION]->(l:Location)\n",
    "    SET l += party.location\n",
    "    \"\"\"\n",
    "        response = await neo4j_driver.execute_query(\n",
    "            import_query, contract=ev.data, path=ev.file_path\n",
    "        )\n",
    "        return StopEvent(response.summary.counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_graph_builder = KnowledgeGraphBuilder(\n",
    "    parser=parser,\n",
    "    affiliate_extract_agent=affiliage_extraction_agent,\n",
    "    branding_extract_agent=cobranding_extraction_agent,\n",
    "    classification_prompt=classification_prompt,\n",
    "    timeout=None,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await knowledge_graph_builder.run(\n",
    "    pdf_path=\"<path to PDF file>\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
