{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5202b22d",
   "metadata": {},
   "source": [
    "# Knowledge Graphs - NCCN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102cff3",
   "metadata": {},
   "source": [
    "## 1. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11302225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9140563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd68e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "LLAMACLOUD_API_KEY=os.getenv(\"LLAMACLOUD_API_KEY\")\n",
    "len(LLAMACLOUD_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9c38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8843e",
   "metadata": {},
   "source": [
    "## 2. Loading & Parsing Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fec320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cloud_services.parse import LlamaParse\n",
    "# Initialize parser with specified mode\n",
    "parser = LlamaParse(\n",
    "    api_key=LLAMACLOUD_API_KEY,\n",
    "    num_workers=4,\n",
    "    verbose=True,\n",
    "    language=\"en\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3705f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 6847207f-9662-48c9-8dcd-113a30fc27b3\n",
      "."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the PDF file to parse\n",
    "pdf_path = \"../data/nccn_breast_cancer.pdf\"\n",
    "\n",
    "# Parse the document asynchronously\n",
    "results = await parser.aparse(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388d77f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fae4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aget_image_data',\n",
       " 'aget_image_documents',\n",
       " 'aget_image_nodes',\n",
       " 'aget_json',\n",
       " 'aget_markdown',\n",
       " 'aget_markdown_documents',\n",
       " 'aget_markdown_nodes',\n",
       " 'aget_text',\n",
       " 'aget_text_documents',\n",
       " 'aget_text_nodes',\n",
       " 'aget_xlsx_data',\n",
       " 'asave_all_images',\n",
       " 'asave_image',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'error',\n",
       " 'file_name',\n",
       " 'from_orm',\n",
       " 'get_image_data',\n",
       " 'get_image_documents',\n",
       " 'get_image_names',\n",
       " 'get_image_nodes',\n",
       " 'get_json',\n",
       " 'get_markdown',\n",
       " 'get_markdown_documents',\n",
       " 'get_markdown_nodes',\n",
       " 'get_text',\n",
       " 'get_text_documents',\n",
       " 'get_text_nodes',\n",
       " 'get_xlsx_data',\n",
       " 'is_done',\n",
       " 'job_id',\n",
       " 'job_metadata',\n",
       " 'json',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'pages',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'save_all_images',\n",
       " 'save_image',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[d for d in dir(results) if not d.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b50d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['charts',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'height',\n",
       " 'images',\n",
       " 'items',\n",
       " 'json',\n",
       " 'layout',\n",
       " 'links',\n",
       " 'md',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'noStructuredContent',\n",
       " 'noTextContent',\n",
       " 'page',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'parsingMode',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'status',\n",
       " 'structuredData',\n",
       " 'tables',\n",
       " 'text',\n",
       " 'triggeredAutoMode',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'width']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page100 = results.pages[100]\n",
    "[d for d in dir(page100) if not d.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f3c2507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Printed by Stina Singel on 6/17/2025 3:05:05 AM. For personal use only. Not approved for distribution. Copyright © 2025 National Comprehensive Cancer Network, Inc., All Rights Reserved.\\n\\n                       NCCN Guidelines Version 4.2025                                                                                                               NCCN Guidelines Index\\n                       Invasive Breast Cancer                                                                                                                           Table of Contents\\n                                                                                                                                                                                         Discussion\\n\\n                                 TARGETED THERAPIES AND ASSOCIATED BIOMARKER TESTING\\n                       FOR RECURRENT UNRESECTABLE (LOCAL OR REGIONAL) OR STAGE IV (M1) DISEASE\\n\\n                                                      REFERENCE'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page100.text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f59d1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPrinted by Stina Singel on 6/17/2025 3:05:05 AM. For personal use only. Not approved for distribution. Copyright © 2025 National Comprehensive Cancer Network, Inc., All Rights Reserved.\\n\\n# NCCN Guidelines Version 4.2025\\n\\n# NCCN Guidelines Index\\n\\n# Invasive Breast Cancer\\n\\n# Table of Contents\\n\\n# Discussion\\n\\n# TARGETED THERAPIES AND ASSOCIATED BIOMARKER TESTING FOR RECURRENT UNRESECTABLE (LOCAL OR REGIONAL) OR STAGE IV (M1) DISEASE\\n\\n# REFERENCES\\n\\n1. Andre F, Ciruelos E, Rubovszky G, et al. Alpelisib for PIK3CA-mutated, hormone receptor-positive advanced breast cancer. N Engl J Med 2019;380:1929-1940.\\n2. Turner NC, Oliveira M, Howell SJ, et al. Capivasertib in hormone receptor–positive advanced breast cancer. N Engl J Med 2023;388:2058-2070.\\n3. Berton D, Banerjee S, Curigliano G, et al. Antitumor activity of dostarlimab in patients with mismatch repair–deficient (dMMR) tumors: a combined analysis of 2 cohorts in the GARNET study. Poster presented at American Society for Clinical Oncology '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page100.md[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c104d894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.charts for p in results.pages if p.charts != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21e05895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.tables for p in results.pages if p.tables != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c82d8e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ImageItem(name='img_p124_1.png', height=167.0, width=486.0, x=23.5500755, y=19.450134299999966, original_width=486, original_height=167, type=None)],\n",
       " [ImageItem(name='img_p125_1.png', height=167.0, width=486.0, x=23.5500755, y=19.450134299999966, original_width=486, original_height=167, type=None),\n",
       "  ImageItem(name='img_p125_2.png', height=729.0, width=729.0, x=221.5500641, y=176.29901130000002, original_width=729, original_height=729, type=None)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.images for p in results.pages if p.images != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16b9d93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.schema import Document\n",
    "documents = [\n",
    "    Document(text=page.md)\n",
    "    for page in results.pages\n",
    "]\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f08535f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# NCCN Clinical Practice Guidelines in Oncology (NCCN Guidelines®)\\n\\n# Breast Cancer\\n\\n# Version 4.2025 — April 17, 2025\\n\\nNCCN.org\\n\\nNCCN recognizes the importance of clinical trials and encourages participation when applicable and available. Trials should be designed to maximize inclusiveness and broad representative enrollment.\\n\\nNCCN Guidelines for Patients® available at www.nccn.org/patients\\n\\nContinue\\n\\nVersion 4.2025, 4/17/25 © 2025 National Comprehensive Cancer Network® (NCCN®), All rights reserved. NCCN Guidelines® and this illustration may not be reproduced in any form without the express written permission of NCCN.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a3e95c",
   "metadata": {},
   "source": [
    "## 3. GraphRAGExtractor\n",
    "\n",
    "The `GraphRAGExtractor` class is designed to extract triples (subject-relation-object) from text and enrich them by adding descriptions for entities and relationships to their properties using an LLM.\n",
    "\n",
    "This functionality is similar to that of the SimpleLLMPathExtractor, but includes additional enhancements to handle entity, relationship descriptions. For guidance on implementation, you may look at similar existing extractors.\n",
    "\n",
    "Here's a breakdown of its functionality:\n",
    "\n",
    "**Key Components**:\n",
    "\n",
    "- llm: The language model used for extraction.\n",
    "- extract_prompt: A prompt template used to guide the LLM in extracting information.\n",
    "- parse_fn: A function to parse the LLM's output into structured data.\n",
    "- max_paths_per_chunk: Limits the number of triples extracted per text chunk.\n",
    "- num_workers: For parallel processing of multiple text nodes.\n",
    "\n",
    "**Main Methods**:\n",
    "\n",
    "- **call**: The entry point for processing a list of text nodes.\n",
    "- acall: An asynchronous version of call for improved performance.\n",
    "- \\_aextract: The core method that processes each individual node.\n",
    "\n",
    "**Extraction Process**:\n",
    "\n",
    "For each input node (chunk of text):\n",
    "\n",
    "1.  It sends the text to the LLM along with the extraction prompt.\n",
    "2.  The LLM's response is parsed to extract entities, relationships, descriptions for entities and relations.\n",
    "3.  Entities are converted into EntityNode objects. Entity description is stored in metadata\n",
    "4.  Relationships are converted into Relation objects. Relationship description is stored in metadata.\n",
    "5.  These are added to the node's metadata under KG_NODES_KEY and KG_RELATIONS_KEY.\n",
    "\n",
    "NOTE: In the current implementation, we are using only relationship descriptions. In the next implementation, we will utilize entity descriptions during the retrieval stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45baa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Callable, Optional, Union, Dict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    "    Relation,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node.\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description in entities:\n",
    "            entity_metadata[\"entity_description\"] = description\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        relation_metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, obj, rel, description = triple\n",
    "            relation_metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj,\n",
    "                target_id=obj,\n",
    "                properties=relation_metadata,\n",
    "            )\n",
    "\n",
    "            existing_relations.append(rel_node)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02dafe",
   "metadata": {},
   "source": [
    "## 4. GraphRAGStore\n",
    "\n",
    "The GraphRAGStore class is an extension of the Neo4jPropertyGraphStoreclass, designed to implement GraphRAG pipeline. Here's a breakdown of its key components and functions:\n",
    "\n",
    "The class uses community detection algorithms to group related nodes in the graph and then it generates summaries for each community using an LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4beb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "from collections import defaultdict\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "\n",
    "class GraphRAGStore(Neo4jPropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    entity_info = None\n",
    "    max_cluster_size = 5\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
    "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
    "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
    "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
    "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
    "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = OpenAI(model=\"gpt-4.1-mini\").chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    def build_communities(self):\n",
    "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
    "        nx_graph = self._create_nx_graph()\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            nx_graph, max_cluster_size=self.max_cluster_size\n",
    "        )\n",
    "        self.entity_info, community_info = self._collect_community_info(\n",
    "            nx_graph, community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info)\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        triplets = self.get_triplets()\n",
    "        for entity1, relation, entity2 in triplets:\n",
    "            nx_graph.add_node(entity1.name)\n",
    "            nx_graph.add_node(entity2.name)\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"\n",
    "        Collect information for each node based on their community,\n",
    "        allowing entities to belong to multiple clusters.\n",
    "        \"\"\"\n",
    "        entity_info = defaultdict(set)\n",
    "        community_info = defaultdict(list)\n",
    "\n",
    "        for item in clusters:\n",
    "            node = item.node\n",
    "            cluster_id = item.cluster\n",
    "\n",
    "            # Update entity_info\n",
    "            entity_info[node].add(cluster_id)\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                if edge_data:\n",
    "                    detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                    community_info[cluster_id].append(detail)\n",
    "\n",
    "        # Convert sets to lists for easier serialization if needed\n",
    "        entity_info = {k: list(v) for k, v in entity_info.items()}\n",
    "\n",
    "        return dict(entity_info), dict(community_info)\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b410f",
   "metadata": {},
   "source": [
    "## 5. GraphRAGQueryEngine\n",
    "\n",
    "The GraphRAGQueryEngine class is a custom query engine designed to process queries using the GraphRAG approach. It leverages the community summaries generated by the GraphRAGStore to answer user queries. Here's a breakdown of its functionality:\n",
    "\n",
    "Main Components:\n",
    "\n",
    "`graph_store`: An instance of GraphRAGStore, which contains the community summaries. llm: A Language Model (LLM) used for generating and aggregating answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39991189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.llms import LLM\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "import re\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    index: PropertyGraphIndex\n",
    "    llm: LLM\n",
    "    similarity_top_k: int = 20\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "\n",
    "        entities = self.get_entities(query_str, self.similarity_top_k)\n",
    "\n",
    "        community_ids = self.retrieve_entity_communities(\n",
    "            self.graph_store.entity_info, entities\n",
    "        )\n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for id, community_summary in community_summaries.items()\n",
    "            if id in community_ids\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def get_entities(self, query_str, similarity_top_k):\n",
    "        nodes_retrieved = self.index.as_retriever(\n",
    "            similarity_top_k=similarity_top_k\n",
    "        ).retrieve(query_str)\n",
    "\n",
    "        enitites = set()\n",
    "        pattern = (\n",
    "            r\"^(\\w+(?:\\s+\\w+)*)\\s*->\\s*([a-zA-Z\\s]+?)\\s*->\\s*(\\w+(?:\\s+\\w+)*)$\"\n",
    "        )\n",
    "\n",
    "        for node in nodes_retrieved:\n",
    "            matches = re.findall(\n",
    "                pattern, node.text, re.MULTILINE | re.IGNORECASE\n",
    "            )\n",
    "\n",
    "            for match in matches:\n",
    "                subject = match[0]\n",
    "                obj = match[2]\n",
    "                enitites.add(subject)\n",
    "                enitites.add(obj)\n",
    "\n",
    "        return list(enitites)\n",
    "\n",
    "    def retrieve_entity_communities(self, entity_info, entities):\n",
    "        \"\"\"\n",
    "        Retrieve cluster information for given entities, allowing for multiple clusters per entity.\n",
    "\n",
    "        Args:\n",
    "        entity_info (dict): Dictionary mapping entities to their cluster IDs (list).\n",
    "        entities (list): List of entity names to retrieve information for.\n",
    "\n",
    "        Returns:\n",
    "        List of community or cluster IDs to which an entity belongs.\n",
    "        \"\"\"\n",
    "        community_ids = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if entity in entity_info:\n",
    "                community_ids.extend(entity_info[entity])\n",
    "\n",
    "        return list(set(community_ids))\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        # intermediate_text = \" \".join(community_answers)\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed3f5c1",
   "metadata": {},
   "source": [
    "## 6. Build End to End GraphRAG Pipeline\n",
    "\n",
    "Now that we have defined all the necessary components, let’s construct the GraphRAG pipeline:\n",
    "\n",
    "1. Create nodes/chunks from the text.\n",
    "2. Build a PropertyGraphIndex using GraphRAGExtractor and GraphRAGStore.\n",
    "3. Construct communities and generate a summary for each community using the graph built above.\n",
    "4. Create a GraphRAGQueryEngine and begin querying.\n",
    "\n",
    "### Create nodes/ chunks from the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d4f40f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = [TextNode(text=document.text) for document in documents]\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# splitter = SentenceSplitter(\n",
    "#     chunk_size=1024,\n",
    "#     chunk_overlap=20,\n",
    "# )\n",
    "# nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06c06b",
   "metadata": {},
   "source": [
    "### Build ProperGraphIndex using GraphRAGExtractor and GraphRAGStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85e0ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
    "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: Type of the entity\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relation: relationship between source_entity and target_entity\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "\n",
    "3. Output Formatting:\n",
    "- Return the result in valid JSON format with two keys: 'entities' (list of entity objects) and 'relationships' (list of relationship objects).\n",
    "- Exclude any text outside the JSON structure (e.g., no explanations or comments).\n",
    "- If no entities or relationships are identified, return empty lists: { \"entities\": [], \"relationships\": [] }.\n",
    "\n",
    "-An Output Example-\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"entity_name\": \"Albert Einstein\",\n",
    "      \"entity_type\": \"Person\",\n",
    "      \"entity_description\": \"Albert Einstein was a theoretical physicist who developed the theory of relativity and made significant contributions to physics.\"\n",
    "    },\n",
    "    {\n",
    "      \"entity_name\": \"Theory of Relativity\",\n",
    "      \"entity_type\": \"Scientific Theory\",\n",
    "      \"entity_description\": \"A scientific theory developed by Albert Einstein, describing the laws of physics in relation to observers in different frames of reference.\"\n",
    "    },\n",
    "    {\n",
    "      \"entity_name\": \"Nobel Prize in Physics\",\n",
    "      \"entity_type\": \"Award\",\n",
    "      \"entity_description\": \"A prestigious international award in the field of physics, awarded annually by the Royal Swedish Academy of Sciences.\"\n",
    "    }\n",
    "  ],\n",
    "  \"relationships\": [\n",
    "    {\n",
    "      \"source_entity\": \"Albert Einstein\",\n",
    "      \"target_entity\": \"Theory of Relativity\",\n",
    "      \"relation\": \"developed\",\n",
    "      \"relationship_description\": \"Albert Einstein is the developer of the theory of relativity.\"\n",
    "    },\n",
    "    {\n",
    "      \"source_entity\": \"Albert Einstein\",\n",
    "      \"target_entity\": \"Nobel Prize in Physics\",\n",
    "      \"relation\": \"won\",\n",
    "      \"relationship_description\": \"Albert Einstein won the Nobel Prize in Physics in 1921.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265aec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def parse_fn(response_str: str) -> Any:\n",
    "    json_pattern = r\"\\{.*\\}\"\n",
    "    match = re.search(json_pattern, response_str, re.DOTALL)\n",
    "    entities = []\n",
    "    relationships = []\n",
    "    if not match:\n",
    "        return entities, relationships\n",
    "    json_str = match.group(0)\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        entities = [\n",
    "            (\n",
    "                entity[\"entity_name\"],\n",
    "                entity[\"entity_type\"],\n",
    "                entity[\"entity_description\"],\n",
    "            )\n",
    "            for entity in data.get(\"entities\", [])\n",
    "        ]\n",
    "        relationships = [\n",
    "            (\n",
    "                relation[\"source_entity\"],\n",
    "                relation[\"target_entity\"],\n",
    "                relation[\"relation\"],\n",
    "                relation[\"relationship_description\"],\n",
    "            )\n",
    "            for relation in data.get(\"relationships\", [])\n",
    "        ]\n",
    "        return entities, relationships\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        return entities, relationships\n",
    "\n",
    "\n",
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=llm,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=2,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd06077",
   "metadata": {},
   "source": [
    "## 7. Docker Setup And Neo4J setup\n",
    "\n",
    "To launch Neo4j locally, first ensure you have docker installed. Then, you can launch the database with the following docker command.\n",
    "\n",
    "```\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1debf552",
   "metadata": {},
   "source": [
    "From here, you can open the db at http://localhost:7474/. On this page, you will be asked to sign in. Use the default username/password of neo4j and neo4j.\n",
    "\n",
    "Once you login for the first time, you will be asked to change the password.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c4eccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = GraphRAGStore(\n",
    "    username=\"neo4j\", password=\"Salesforce1\", url=\"bolt://localhost:7687\", # database=\"nccn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 263/263 [06:20<00:00,  1.45s/it]\n",
      "Generating embeddings: 100%|██████████| 3/3 [00:01<00:00,  1.80it/s]\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:01<00:00,  9.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20871e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EntityNode(label='Organization', embedding=None, properties={'id': 'National Comprehensive Cancer Network', 'entity_description': 'A not-for-profit alliance of leading cancer centers dedicated to improving the quality, effectiveness, and efficiency of cancer care.', 'triplet_source_id': 'e4b6e5ee-99e9-4bfc-bfeb-cc9e95b42f1c'}, name='National Comprehensive Cancer Network'),\n",
       " Relation(label='recommends', source_id='National Comprehensive Cancer Network', target_id='Abemaciclib', properties={'triplet_source_id': 'eb077e13-7ae1-4b28-9c12-bd5cd739b710', 'relationship_description': 'The NCCN publishes guidelines recommending the use of abemaciclib as adjuvant endocrine therapy in eligible invasive breast cancer patients.'}),\n",
       " EntityNode(label='Drug', embedding=None, properties={'id': 'Abemaciclib', 'entity_description': 'Abemaciclib is a drug used in combination with fulvestrant for women with hormone receptor-positive, HER2-negative advanced breast cancer who have progressed while receiving endocrine therapy.', 'triplet_source_id': '55663413-1f13-41cc-a4b1-c67dffdcb5f4'}, name='Abemaciclib')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c958600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'National Comprehensive Cancer Network',\n",
       " 'entity_description': 'A not-for-profit alliance of leading cancer centers dedicated to improving the quality, effectiveness, and efficiency of cancer care.',\n",
       " 'triplet_source_id': 'e4b6e5ee-99e9-4bfc-bfeb-cc9e95b42f1c'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][0].properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48eb2c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'triplet_source_id': 'eb077e13-7ae1-4b28-9c12-bd5cd739b710',\n",
       " 'relationship_description': 'The NCCN publishes guidelines recommending the use of abemaciclib as adjuvant endocrine therapy in eligible invasive breast cancer patients.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.get_triplets()[10][1].properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea0be0",
   "metadata": {},
   "source": [
    "### Build communities\n",
    "\n",
    "This will create communities and summary for each community.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4934cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb1f63d",
   "metadata": {},
   "source": [
    "## 8. Create Query Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2c214f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store, \n",
    "    llm=llm,\n",
    "    index=index,\n",
    "    similarity_top_k=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33ff10b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The National Comprehensive Cancer Network (NCCN) guidelines recommend a multidisciplinary, evidence-based approach for treating HER2-positive breast cancer that centers on HER2-targeted therapies combined with chemotherapy, surgery, and radiation as appropriate. Key elements include:\n",
       "\n",
       "- **HER2-Targeted Therapy:** Trastuzumab is the cornerstone agent, administered typically for up to one year in the adjuvant setting. Pertuzumab is often added, especially in neoadjuvant and adjuvant regimens for node-positive disease, improving invasive disease-free survival. For metastatic HER2-positive breast cancer, agents such as ado-trastuzumab emtansine (T-DM1), tucatinib (combined with trastuzumab and capecitabine), and fam-trastuzumab deruxtecan-nxki are recommended based on clinical trial evidence.\n",
       "\n",
       "- **Chemotherapy:** Taxanes, particularly paclitaxel and docetaxel, are commonly combined with HER2-targeted therapies. Anthracycline-based regimens (e.g., doxorubicin and cyclophosphamide) followed by taxanes plus trastuzumab are standard in many cases. Chemotherapy choice may be tailored considering efficacy and side effect profiles.\n",
       "\n",
       "- **Endocrine Therapy:** For patients with hormone receptor-positive, HER2-positive breast cancer, combining HER2-targeted therapy (e.g., trastuzumab) with endocrine agents such as anastrozole is effective, especially in metastatic settings, as demonstrated in trials like TAnDEM.\n",
       "\n",
       "- **Surgery and Radiation:** Surgical options include breast-conserving surgery or mastectomy with sentinel lymph node biopsy or axillary dissection as indicated. Radiation therapy is recommended postoperatively based on surgical and pathological findings and can be safely administered concurrently with HER2-targeted agents.\n",
       "\n",
       "- **Diagnostic and Staging:** Accurate HER2 testing per ASCO/CAP guidelines is essential to confirm HER2 status and guide therapy. Imaging modalities such as FDG-PET/CT are advised for staging, particularly in advanced or recurrent disease.\n",
       "\n",
       "- **Genetic Testing:** Germline BRCA1/2 mutation testing is recommended in recurrent or metastatic cases to inform potential use of PARP inhibitors, although these are not standard for HER2-positive disease.\n",
       "\n",
       "In summary, the best treatment for HER2-positive breast cancer involves confirmed HER2 status followed by a tailored, multidisciplinary regimen combining trastuzumab-based HER2-targeted therapies with chemotherapy (commonly taxanes), appropriate endocrine therapy if hormone receptor-positive, and individualized surgical and radiation management, all guided by NCCN evidence-based protocols and clinical trial data to optimize patient outcomes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"How best to treat breast cancer for patients with HER2?\")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
